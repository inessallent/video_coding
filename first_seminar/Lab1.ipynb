{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUkA7KW-vKAq"
   },
   "source": [
    "# Seminar_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBto_YUV:\n",
    "    def YUV_to_RGB(Y, U,V):\n",
    "        B = round(1.163 * (Y -16) + 2.018 * (U - 128))\n",
    "        G = round(1.164 * (Y - 16) - 0.813 * (V - 128) - 0.391 * (U - 128))\n",
    "        R = round(1.164 * (Y - 16) + 1.596 * (V - 128)) \n",
    "        return(R, G, B)\n",
    "    \n",
    "    def RGB_to_YUV(R,G,B):\n",
    "        Y = round(0.257 * R + 0.504 * G + 0.098 * B +16)\n",
    "        U = round(-0.148 * R - 0.291 * G + 0.439 * B +128)\n",
    "        V = round(0.439 * R - 0.368 * G - 0.071 * B +128)\n",
    "        return(Y,U,V)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores RGB: R = 98, G = 98, B = 98\n"
     ]
    }
   ],
   "source": [
    "Y, U, V = 100, 128, 128\n",
    "\n",
    "# Convertir YUV a RGB\n",
    "R, G, B = RGBto_YUV.YUV_to_RGB(Y, U, V)\n",
    "print(f\"Valores RGB: R = {R}, G = {G}, B = {B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores YUV: Y = 100, U = 128, V = 128\n"
     ]
    }
   ],
   "source": [
    "# Convertir RGB a YUV\n",
    "Y, U, V = RGBto_YUV.RGB_to_YUV(R, G, B)\n",
    "print(f\"Valores YUV: Y = {Y}, U = {U}, V = {V}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resized image saved to output_320x240.jpg\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "input_image = \"/Users/viktoriaolmedo/Downloads/escut-barca.png\"\n",
    "output_image = \"output_320x240.jpg\"\n",
    "#modificar per path de cada ordinador\n",
    "\n",
    "\n",
    "def resize_image(input_image, output_image, width, height, quality = 28):\n",
    "\n",
    "    command = [\"ffmpeg\",\"-y\",\"-loglevel\", \"info\",\"-i\", input_image,\"-vf\", f\"scale={width}:{height}\",output_image ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(result.stdout)\n",
    "        print(f\"Resized image saved to {output_image}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error ocurred while running FFmpeg\", e.stderr)\n",
    "\n",
    "\n",
    "#ffmpeg -i input.jpg -vf scale=320:240 output_320x240.png\n",
    "\n",
    "resize_image(input_image, output_image, 320, 240, quality=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "We first implement it with a matrix 8x8 in order to check if the algorithm is really working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz 8x8:\n",
      "[[ 1  2  3  4  5  6  7  8]\n",
      " [ 9 10 11 12 13 14 15 16]\n",
      " [17 18 19 20 21 22 23 24]\n",
      " [25 26 27 28 29 30 31 32]\n",
      " [33 34 35 36 37 38 39 40]\n",
      " [41 42 43 44 45 46 47 48]\n",
      " [49 50 51 52 53 54 55 56]\n",
      " [57 58 59 60 61 62 63 64]]\n",
      "\n",
      "Recorrido Zig-Zag:\n",
      "[1, 2, 9, 17, 10, 3, 4, 11, 18, 25, 33, 26, 19, 12, 5, 6, 13, 20, 27, 34, 41, 49, 42, 35, 28, 21, 14, 7, 8, 15, 22, 29, 36, 43, 50, 57, 58, 51, 44, 37, 30, 23, 16, 24, 31, 38, 45, 52, 59, 60, 53, 46, 39, 32, 40, 47, 54, 61, 62, 55, 48, 56, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.arange(1, 65).reshape(8, 8)\n",
    "\n",
    "def zigzag_traversal(matrix):\n",
    "    result = [None] * 64  \n",
    "    n = matrix.shape[0]  \n",
    "    \n",
    "    a = 0  \n",
    "    i = 0 \n",
    "    j = 0 \n",
    "    result[a] = matrix[i][j]  # First value\n",
    "    \n",
    "    while a < 63:  \n",
    "        #step 1: (one to the right)\n",
    "        if j == n - 1:  \n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < 64:\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 2: (Diagonal down to the left until reaching j = 0)\n",
    "        while i + 1 < n and j - 1 >= 0 and a < 63:\n",
    "            i += 1\n",
    "            j -= 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 3: (one down) \n",
    "        if i == n - 1:  \n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < 64:\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 4: (Diagonal up to the right until reaching i = 0)\n",
    "        while j + 1 < n and i - 1 >= 0 and a < 63:\n",
    "            i -= 1\n",
    "            j += 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i][j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Obtener el recorrido zig-zag\n",
    "zigzag_result = zigzag_traversal(matrix)\n",
    "\n",
    "# Mostrar la matriz y el recorrido zig-zag\n",
    "print(\"Matriz 8x8:\")\n",
    "print(matrix)\n",
    "print(\"\\nRecorrido Zig-Zag:\")\n",
    "print(zigzag_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we implemented for images. We use the resize_image function generated in the previous exercise in order to obtain a nxn image. Then we implement the zig zag function and obtain the expected output. First we implemented in Black and White, but then we realize that maybe it was needed to implemented for rgb images, so we added it to the code.\n",
    "\n",
    "We can try and change the values of the resize image. In order to check if the algorithm is still working for this case with images, we have set the values to 16, because then we can see the complete matrix. \n",
    "Then we change it to a bigger value, 420 in this case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image_bw\u001b[39m(image_path):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess\n",
    "\n",
    "def load_image_bw(image_path):\n",
    "    return cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n",
    "\n",
    "def load_image_rgb(image_path):\n",
    "    return cv2.imread(image_path)  \n",
    "\n",
    "def serpentine(matrix):\n",
    "    n = matrix.shape[0]  \n",
    "    result = [None] * (n * n)  \n",
    "    \n",
    "    a = 0  \n",
    "    i = 0 \n",
    "    j = 0 \n",
    "    result[a] = matrix[i, j]  # First value\n",
    "    \n",
    "    while a < n * n - 1:  \n",
    "        #step 1: (one to the right)\n",
    "        if j == n - 1:  \n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < n * n:\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 2: (Diagonal down to the left until reaching j = 0)\n",
    "        while i + 1 < n and j - 1 >= 0 and a < n * n - 1:\n",
    "            i += 1\n",
    "            j -= 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 3: (one down)\n",
    "        if i == n - 1:  \n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < n * n:\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 4: (Diagonal up to the right until reaching i = 0)\n",
    "        while j + 1 < n and i - 1 >= 0 and a < n * n - 1:\n",
    "            i -= 1\n",
    "            j += 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i, j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Inputs and Outputs\n",
    "image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/first_seminar/logo_fcb.jpeg\"\n",
    "input_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/first_seminar/logo_fcb_resize.jpeg\"\n",
    "resize_image(image, input_image, 420, 420, quality=28)\n",
    "output_image_bw = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/first_seminar/serpentine_bw.jpeg\"\n",
    "output_image_rgb = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/first_seminar/serpentine_rgb.jpeg\"\n",
    "\n",
    "##################### Black and White case #####################################\n",
    "\n",
    "#We load the resize image in BW\n",
    "image_bw = load_image_bw(input_image)\n",
    "\n",
    "if image_bw is None:\n",
    "    print(\"Error loading the BW image\")\n",
    "else:\n",
    "    # Print the matrix to then check it the convertion is done well. \n",
    "    print(\"Original Matrix in Black and White:\")\n",
    "    print(image_bw)\n",
    "\n",
    "\n",
    "# Check if it's a nxn matrix\n",
    "if image_bw is None:\n",
    "    print(\"Error loading the BW image\")\n",
    "else:\n",
    "    assert image_bw.shape[0] == image_bw.shape[1], \"The resize BW image is not nxn.\"\n",
    "\n",
    "    serpentine_result_bw = serpentine(image_bw)\n",
    "\n",
    "    print(\"Serpentine of image in Black and White:\")\n",
    "    print(serpentine_result_bw)\n",
    "\n",
    "    n = image_bw.shape[0]\n",
    "    serpentine_image_bw = np.array(serpentine_result_bw).reshape((n, n))\n",
    "\n",
    "    # Safe the output\n",
    "    cv2.imwrite(output_image_bw, serpentine_image_bw)\n",
    "    print(f\"Output in BW safe in: {output_image_bw}\")\n",
    "\n",
    "\n",
    "############################# RGB CASE ############################\n",
    "def serpentine_color(image):\n",
    "    channels = cv2.split(image)  # Separate into B, G, and R channels\n",
    "    serpentine_channels = []\n",
    "\n",
    "    for idx, channel in enumerate(channels):\n",
    "        serpentine_result = serpentine(channel)\n",
    "        \n",
    "        # Print serpentine result for each channel\n",
    "        print(f\"Serpentine traversal output for channel {idx}:\")\n",
    "        print(serpentine_result)\n",
    "        \n",
    "        n = channel.shape[0]\n",
    "        serpentine_matrix = np.array(serpentine_result).reshape((n, n))\n",
    "        serpentine_channels.append(serpentine_matrix)\n",
    "\n",
    "    # Merge channels back into a color image\n",
    "    serpentine_image_color = cv2.merge(serpentine_channels)\n",
    "    return serpentine_image_color\n",
    "\n",
    "\n",
    "#We load the resize image in BW\n",
    "image_rgb = load_image_rgb(input_image)\n",
    "\n",
    "\n",
    "if image_rgb is None:\n",
    "    print(\"Error loading the image in rgb\")\n",
    "else:\n",
    "    # Print the matrix to then check it the conversion is done well. \n",
    "    print(\"Original Matrix rgb:\")\n",
    "    print(image_rgb)\n",
    "\n",
    "\n",
    "if image_rgb is None:\n",
    "    print(\"Error loading the image\")\n",
    "else:\n",
    "    # Check image is nxn\n",
    "    assert image_rgb.shape[0] == image_rgb.shape[1], \"Input image rgb is not nxn.\"\n",
    "    \n",
    "    serpentine_result_rbg = serpentine_color(image_rgb)\n",
    "    \n",
    "    print(\"Output matrix of rgb image\",serpentine_result_rbg)\n",
    "    \n",
    "    cv2.imwrite(output_image_rgb, serpentine_result_rbg)\n",
    "    print(f\"Serpentine image in rgb safe in: {output_image_rgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_image_rgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFMPEG failed with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m output_image_compressed \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/first_seminar/output_image_compressed.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m compress_to_bw(\u001b[43moutput_image_rgb\u001b[49m, output_image_compressed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_image_rgb' is not defined"
     ]
    }
   ],
   "source": [
    "def compress_to_bw(input_image_path, output_image_path):\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            'ffmpeg', '-i', input_image_path, \n",
    "            '-vf', 'format=gray',  # Convert to black and white\n",
    "            '-compression_level', '10',  # Max compression for PNG (range 0-10)\n",
    "            '-qscale:v', '31',  # Highest compression for JPEG (range 2-31)\n",
    "            '-y', output_image_path\n",
    "        ], check=True)\n",
    "        \n",
    "        print(f\"Compressed and converted image saved at: {output_image_path}\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"FFMPEG failed with error: {e}\")\n",
    "\n",
    "output_image_compressed = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/first_seminar/output_image_compressed.jpeg\"\n",
    "compress_to_bw(output_image_rgb, output_image_compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 3, 65, 3, 66, 2, 67, 1, 68, 2, 65]\n"
     ]
    }
   ],
   "source": [
    "def encoding(byte_sequence):\n",
    "    if not isinstance(byte_sequence, (bytes, bytearray)):\n",
    "        raise ValueError(\"Input must be a bytes or bytearray object.\")\n",
    "    \n",
    "    encoded_bytes = bytearray()\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(byte_sequence):\n",
    "        count = 1\n",
    "        current_byte = byte_sequence[i]\n",
    "        j = i\n",
    "\n",
    "        while j < len(byte_sequence) - 1:\n",
    "            if byte_sequence[j] == byte_sequence[j + 1]:\n",
    "                count += 1\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        encoded_bytes.append(count)\n",
    "        encoded_bytes.append(current_byte)\n",
    "        \n",
    "        i = j + 1\n",
    "    \n",
    "    return bytes(encoded_bytes)\n",
    "\n",
    "input_bytes = bytes([0, 65, 65, 65, 66, 66, 66, 67, 67, 68, 65, 65])\n",
    "encoded_result = encoding(input_bytes)\n",
    "print(list(encoded_result))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCT Result:\n",
      " [[ 6.100e+02 -2.911e+01 -6.194e+01  2.533e+01  5.475e+01 -1.972e+01\n",
      "  -5.900e-01  2.080e+00]\n",
      " [ 6.080e+00 -2.059e+01 -6.163e+01  8.010e+00  1.153e+01 -6.640e+00\n",
      "  -6.420e+00  6.780e+00]\n",
      " [-4.609e+01  7.960e+00  7.673e+01 -2.559e+01 -2.966e+01  1.014e+01\n",
      "   6.390e+00 -4.770e+00]\n",
      " [-4.891e+01  1.177e+01  3.431e+01 -1.423e+01 -9.860e+00  6.190e+00\n",
      "   1.340e+00  1.500e+00]\n",
      " [ 1.075e+01 -7.630e+00 -1.245e+01 -2.040e+00 -5.000e-01  1.370e+00\n",
      "  -4.580e+00  1.520e+00]\n",
      " [-9.640e+00  1.410e+00  3.410e+00 -3.290e+00 -4.700e-01  4.200e-01\n",
      "   1.810e+00 -3.900e-01]\n",
      " [-2.830e+00 -1.230e+00  1.390e+00  8.000e-02  9.200e-01 -3.510e+00\n",
      "   1.770e+00 -2.770e+00]\n",
      " [-1.250e+00 -7.100e-01 -4.900e-01 -2.690e+00 -9.000e-02 -4.000e-01\n",
      "  -9.100e-01  4.100e-01]]\n",
      "\n",
      "Reconstructed Block:\n",
      " [[ 52.  55.  61.  66.  70.  61.  64.  73.]\n",
      " [ 63.  59.  66.  90. 109.  85.  69.  72.]\n",
      " [ 62.  59.  68. 113. 144. 104.  66.  73.]\n",
      " [ 63.  58.  71. 122. 154. 106.  70.  69.]\n",
      " [ 67.  61.  68. 104. 126.  88.  68.  70.]\n",
      " [ 79.  65.  60.  70.  77.  68.  58.  75.]\n",
      " [ 85.  71.  64.  59.  55.  61.  65.  83.]\n",
      " [ 87.  79.  69.  68.  65.  76.  78.  94.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "class DCTProcessor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def apply_dct(self, block):\n",
    "        if not isinstance(block, np.ndarray):\n",
    "            raise ValueError(\"Input block must be a numpy array.\")\n",
    "        \n",
    "        # Apply 2D DCT (type-II) along both axes\n",
    "        return dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    def apply_idct(self, dct_block):\n",
    "        if not isinstance(dct_block, np.ndarray):\n",
    "            raise ValueError(\"Input DCT block must be a numpy array.\")\n",
    "        \n",
    "        return idct(idct(dct_block.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "# Example:\n",
    "if __name__ == \"__main__\":\n",
    "    dct_processor = DCTProcessor()\n",
    "\n",
    "    block = np.array([\n",
    "        [52, 55, 61, 66, 70, 61, 64, 73],\n",
    "        [63, 59, 66, 90, 109, 85, 69, 72],\n",
    "        [62, 59, 68, 113, 144, 104, 66, 73],\n",
    "        [63, 58, 71, 122, 154, 106, 70, 69],\n",
    "        [67, 61, 68, 104, 126, 88, 68, 70],\n",
    "        [79, 65, 60, 70, 77, 68, 58, 75],\n",
    "        [85, 71, 64, 59, 55, 61, 65, 83],\n",
    "        [87, 79, 69, 68, 65, 76, 78, 94]\n",
    "    ])\n",
    "\n",
    "    # Apply DCT\n",
    "    dct_block = dct_processor.apply_dct(block)\n",
    "    print(\"DCT Result:\\n\", np.round(dct_block, 2))\n",
    "\n",
    "    # Apply IDCT to reconstruct\n",
    "    reconstructed_block = dct_processor.apply_idct(dct_block)\n",
    "    print(\"\\nReconstructed Block:\\n\", np.round(reconstructed_block, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1004.          -57.72015737  -22.62145031  -26.96553606   28.28427125\n",
      "   -12.33157164   -2.87575832    9.65275291]\n",
      " [1226.          -62.80862838 -135.86001805   47.31686293   77.78174593\n",
      "   -29.39383609   -6.48502085   13.27377425]\n",
      " [1378.          -85.31450748 -261.39884858   89.50082767  134.35028843\n",
      "   -64.08917035   -6.53008144    4.42887148]\n",
      " [1426.          -83.10039098 -303.58028174   98.91599692  145.66399692\n",
      "   -49.9983738   -19.67263434   15.55998681]\n",
      " [1304.          -48.33206974 -192.50649839   61.4189483   115.96551211\n",
      "   -33.99070329  -21.28962366   16.50320918]\n",
      " [1104.            7.86646858    9.10747913   27.39104014   70.71067812\n",
      "   -24.04845179   14.59636338   -5.78978056]\n",
      " [1086.           18.79492044  108.19802502   -9.34447896   29.69848481\n",
      "    -1.7248436    21.00446098   -8.74394608]\n",
      " [1232.          -18.67549603   97.8768375    -1.63318269   16.97056275\n",
      "    -7.48200066   14.56450073  -21.36769123]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import fft \n",
    "\n",
    "block = np.array([\n",
    "    [52, 55, 61, 66, 70, 61, 64, 73],\n",
    "    [63, 59, 66, 90, 109, 85, 69, 72],\n",
    "    [62, 59, 68, 113, 144, 104, 66, 73],\n",
    "    [63, 58, 71, 122, 154, 106, 70, 69],\n",
    "    [67, 61, 68, 104, 126, 88, 68, 70],\n",
    "    [79, 65, 60, 70, 77, 68, 58, 75],\n",
    "    [85, 71, 64, 59, 55, 61, 65, 83],\n",
    "    [87, 79, 69, 68, 65, 76, 78, 94]\n",
    "])\n",
    "\n",
    "gfg = fft.dct(block) \n",
    "\n",
    "print(gfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1004.        ,  -57.72015737,  -22.62145031,  -26.96553606,\n",
       "          28.28427125,  -12.33157164,   -2.87575832,    9.65275291],\n",
       "       [1226.        ,  -62.80862838, -135.86001805,   47.31686293,\n",
       "          77.78174593,  -29.39383609,   -6.48502085,   13.27377425],\n",
       "       [1378.        ,  -85.31450748, -261.39884858,   89.50082767,\n",
       "         134.35028843,  -64.08917035,   -6.53008144,    4.42887148],\n",
       "       [1426.        ,  -83.10039098, -303.58028174,   98.91599692,\n",
       "         145.66399692,  -49.9983738 ,  -19.67263434,   15.55998681],\n",
       "       [1304.        ,  -48.33206974, -192.50649839,   61.4189483 ,\n",
       "         115.96551211,  -33.99070329,  -21.28962366,   16.50320918],\n",
       "       [1104.        ,    7.86646858,    9.10747913,   27.39104014,\n",
       "          70.71067812,  -24.04845179,   14.59636338,   -5.78978056],\n",
       "       [1086.        ,   18.79492044,  108.19802502,   -9.34447896,\n",
       "          29.69848481,   -1.7248436 ,   21.00446098,   -8.74394608],\n",
       "       [1232.        ,  -18.67549603,   97.8768375 ,   -1.63318269,\n",
       "          16.97056275,   -7.48200066,   14.56450073,  -21.36769123]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.fftpack import dct\n",
    "\n",
    "dct(block, 2)\n",
    "\n",
    "#type=1 (DCT-I): This type is less commonly used. It has specific boundary conditions where the input and output are symmetric, meaning that the first and last elements are half-weighted.\n",
    "#type=2 (DCT-II): This is the most commonly used type, especially in image compression (e.g., JPEG). It transforms a real input array into a real output array, with no symmetry in the boundary conditions.\n",
    "#type=3 (DCT-III): This type is the inverse of DCT-II.\n",
    "#type=4 (DCT-IV): Less common and typically used in specialized applications.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMRLfTamI1Guef8I/9SvpXQ",
   "mount_file_id": "1zG2m0ccomnArDcFgJIhztc_vM1FDdex0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

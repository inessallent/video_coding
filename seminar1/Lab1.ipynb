{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUkA7KW-vKAq"
   },
   "source": [
    "# Seminar_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBto_YUV:\n",
    "    def YUV_to_RGB(self, Y,U,V):\n",
    "        B = round(1.163 * (Y -16) + 2.018 * (U - 128))\n",
    "        G = round(1.164 * (Y - 16) - 0.813 * (V - 128) - 0.391 * (U - 128))\n",
    "        R = round(1.164 * (Y - 16) + 1.596 * (V - 128)) \n",
    "        return(R, G, B)\n",
    "    \n",
    "    def RGB_to_YUV(self, R,G,B):\n",
    "        Y = round(0.257 * R + 0.504 * G + 0.098 * B +16)\n",
    "        U = round(-0.148 * R - 0.291 * G + 0.439 * B +128)\n",
    "        V = round(0.439 * R - 0.368 * G - 0.071 * B +128)\n",
    "        return(Y,U,V)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores RGB: R = 98, G = 98, B = 98\n"
     ]
    }
   ],
   "source": [
    "Y, U, V = 100, 128, 128\n",
    "\n",
    "# Convertir YUV a RGB\n",
    "converter = RGBto_YUV()\n",
    "R, G, B = converter.YUV_to_RGB(Y, U, V)\n",
    "print(f\"Valores RGB: R = {R}, G = {G}, B = {B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores YUV: Y = 100, U = 128, V = 128\n"
     ]
    }
   ],
   "source": [
    "# Convertir RGB a YUV\n",
    "Y, U, V = converter.RGB_to_YUV(R, G, B)\n",
    "print(f\"Valores YUV: Y = {Y}, U = {U}, V = {V}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "def resize_image(input_image, output_image, width, height, quality = 28):\n",
    "\n",
    "    command = [\"ffmpeg\",\"-y\",\"-loglevel\", \"info\",\"-i\", input_image,\"-vf\", f\"scale={width}:{height}\"]\n",
    "\n",
    "    if quality is not None:\n",
    "        command.extend([\"-q:v\", str(quality)])\n",
    "    \n",
    "    command.append(output_image)\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(result.stdout)\n",
    "        print(f\"Resized image saved to {output_image}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error ocurred while running FFmpeg\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "We first implement it with a matrix 8x8 in order to check if the algorithm is really working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz 8x8:\n",
      "[[ 1  2  3  4  5  6  7  8]\n",
      " [ 9 10 11 12 13 14 15 16]\n",
      " [17 18 19 20 21 22 23 24]\n",
      " [25 26 27 28 29 30 31 32]\n",
      " [33 34 35 36 37 38 39 40]\n",
      " [41 42 43 44 45 46 47 48]\n",
      " [49 50 51 52 53 54 55 56]\n",
      " [57 58 59 60 61 62 63 64]]\n",
      "\n",
      "Recorrido Zig-Zag:\n",
      "[1, 2, 9, 17, 10, 3, 4, 11, 18, 25, 33, 26, 19, 12, 5, 6, 13, 20, 27, 34, 41, 49, 42, 35, 28, 21, 14, 7, 8, 15, 22, 29, 36, 43, 50, 57, 58, 51, 44, 37, 30, 23, 16, 24, 31, 38, 45, 52, 59, 60, 53, 46, 39, 32, 40, 47, 54, 61, 62, 55, 48, 56, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.arange(1, 65).reshape(8, 8)\n",
    "\n",
    "def zigzag_traversal(matrix):\n",
    "    result = [None] * 64  \n",
    "    n = matrix.shape[0]  \n",
    "    \n",
    "    a = 0  \n",
    "    i = 0 \n",
    "    j = 0 \n",
    "    result[a] = matrix[i][j]  # First value\n",
    "    \n",
    "    while a < 63:  \n",
    "        #step 1: (one to the right)\n",
    "        if j == n - 1:  \n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < 64:\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 2: (Diagonal down to the left until reaching j = 0)\n",
    "        while i + 1 < n and j - 1 >= 0 and a < 63:\n",
    "            i += 1\n",
    "            j -= 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 3: (one down) \n",
    "        if i == n - 1:  \n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < 64:\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 4: (Diagonal up to the right until reaching i = 0)\n",
    "        while j + 1 < n and i - 1 >= 0 and a < 63:\n",
    "            i -= 1\n",
    "            j += 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i][j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Obtener el recorrido zig-zag\n",
    "zigzag_result = zigzag_traversal(matrix)\n",
    "\n",
    "# Mostrar la matriz y el recorrido zig-zag\n",
    "print(\"Matriz 8x8:\")\n",
    "print(matrix)\n",
    "print(\"\\nRecorrido Zig-Zag:\")\n",
    "print(zigzag_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we implemented for images. We use the resize_image function generated in the previous exercise in order to obtain a nxn image. Then we implement the zig zag function and obtain the expected output. First we implemented in Black and White, but then we realize that maybe it was needed to implemented for rgb images, so we added it to the code.\n",
    "\n",
    "We can try and change the values of the resize image. In order to check if the algorithm is still working for this case with images, we have set the values to 16, because then we can see the complete matrix. \n",
    "Then we change it to a bigger value, 420 in this case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resized image saved to /Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_resize.jpeg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess\n",
    "\n",
    "def load_image_bw(image_path):\n",
    "    return cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n",
    "\n",
    "def load_image_rgb(image_path):\n",
    "    return cv2.imread(image_path)  \n",
    "\n",
    "def serpentine(matrix):\n",
    "    n = matrix.shape[0]  \n",
    "    result = [None] * (n * n)  \n",
    "    \n",
    "    a = 0  \n",
    "    i = 0 \n",
    "    j = 0 \n",
    "    result[a] = matrix[i, j]  # First value\n",
    "    \n",
    "    while a < n * n - 1:  \n",
    "        #step 1: (one to the right)\n",
    "        if j == n - 1:  \n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < n * n:\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 2: (Diagonal down to the left until reaching j = 0)\n",
    "        while i + 1 < n and j - 1 >= 0 and a < n * n - 1:\n",
    "            i += 1\n",
    "            j -= 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 3: (one down)\n",
    "        if i == n - 1:  \n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < n * n:\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 4: (Diagonal up to the right until reaching i = 0)\n",
    "        while j + 1 < n and i - 1 >= 0 and a < n * n - 1:\n",
    "            i -= 1\n",
    "            j += 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i, j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Inputs and Outputs\n",
    "image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb.jpeg\"\n",
    "input_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_resize.jpeg\"\n",
    "resize_image(image, input_image, 420, 420, quality=28)\n",
    "# output_image_bw = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/serpentine_bw.jpeg\"\n",
    "# output_image_rgb = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/serpentine_rgb.jpeg\"\n",
    "\n",
    "##################### Black and White case #####################################\n",
    "\n",
    "# #We load the resize image in BW\n",
    "# image_bw = load_image_bw(input_image)\n",
    "\n",
    "# if image_bw is None:\n",
    "#     print(\"Error loading the BW image\")\n",
    "# else:\n",
    "#     # Print the matrix to then check it the convertion is done well. \n",
    "#     print(\"Original Matrix in Black and White:\")\n",
    "#     print(image_bw)\n",
    "\n",
    "\n",
    "# # Check if it's a nxn matrix\n",
    "# if image_bw is None:\n",
    "#     print(\"Error loading the BW image\")\n",
    "# else:\n",
    "#     assert image_bw.shape[0] == image_bw.shape[1], \"The resize BW image is not nxn.\"\n",
    "\n",
    "#     serpentine_result_bw = serpentine(image_bw)\n",
    "\n",
    "#     print(\"Serpentine of image in Black and White:\")\n",
    "#     print(serpentine_result_bw)\n",
    "\n",
    "#     n = image_bw.shape[0]\n",
    "#     serpentine_image_bw = np.array(serpentine_result_bw).reshape((n, n))\n",
    "\n",
    "#     # Safe the output\n",
    "#     # cv2.imwrite(output_image_bw, serpentine_image_bw)\n",
    "#     # print(f\"Output in BW safe in: {output_image_bw}\")\n",
    "\n",
    "\n",
    "############################# RGB CASE ############################\n",
    "def serpentine_color(image):\n",
    "    channels = cv2.split(image)  # Separate into B, G, and R channels\n",
    "    serpentine_channels = []\n",
    "\n",
    "    for idx, channel in enumerate(channels):\n",
    "        serpentine_result = serpentine(channel)\n",
    "        \n",
    "        # Print serpentine result for each channel\n",
    "        print(f\"Serpentine traversal output for channel {idx}:\")\n",
    "        print(serpentine_result)\n",
    "        \n",
    "        n = channel.shape[0]\n",
    "        serpentine_matrix = np.array(serpentine_result).reshape((n, n))\n",
    "        serpentine_channels.append(serpentine_matrix)\n",
    "\n",
    "    # Merge channels back into a color image\n",
    "    serpentine_image_color = cv2.merge(serpentine_channels)\n",
    "    return serpentine_image_color\n",
    "\n",
    "\n",
    "# #We load the resize image in BW\n",
    "# image_rgb = load_image_rgb(input_image)\n",
    "\n",
    "\n",
    "# if image_rgb is None:\n",
    "#     print(\"Error loading the image in rgb\")\n",
    "# else:\n",
    "#     # Print the matrix to then check it the conversion is done well. \n",
    "#     print(\"Original Matrix rgb:\")\n",
    "#     print(image_rgb)\n",
    "\n",
    "\n",
    "# if image_rgb is None:\n",
    "#     print(\"Error loading the image\")\n",
    "# else:\n",
    "#     # Check image is nxn\n",
    "#     assert image_rgb.shape[0] == image_rgb.shape[1], \"Input image rgb is not nxn.\"\n",
    "    \n",
    "#     serpentine_result_rbg = serpentine_color(image_rgb)\n",
    "    \n",
    "#     print(\"Output matrix of rgb image\",serpentine_result_rbg)\n",
    "    \n",
    "#     # cv2.imwrite(output_image_rgb, serpentine_result_rbg)\n",
    "#     # print(f\"Serpentine image in rgb safe in: {output_image_rgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**\n",
    "We transform the rgb output to Black and White. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_to_bw(input_image_path, output_image_path):\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            'ffmpeg', '-i', input_image_path, \n",
    "            '-vf', 'format=gray',  # Convert to black and white\n",
    "            '-compression_level', '10',  # Max compression for PNG (range 0-10)\n",
    "            '-qscale:v', '31',  # Highest compression for JPEG (range 2-31)\n",
    "            '-y', output_image_path\n",
    "        ], check=True)\n",
    "        \n",
    "        print(f\"Compressed and converted image saved at: {output_image_path}\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"FFMPEG failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(byte_sequence):\n",
    "    if not isinstance(byte_sequence, (bytes, bytearray)):\n",
    "        raise ValueError(\"Input must be a bytes or bytearray object.\")\n",
    "    \n",
    "    encoded_bytes = bytearray()\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(byte_sequence):\n",
    "        count = 1\n",
    "        current_byte = byte_sequence[i]\n",
    "        j = i\n",
    "\n",
    "        while j < len(byte_sequence) - 1:\n",
    "            if byte_sequence[j] == byte_sequence[j + 1]:\n",
    "                count += 1\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        encoded_bytes.append(count)\n",
    "        encoded_bytes.append(current_byte)\n",
    "        \n",
    "        i = j + 1\n",
    "    \n",
    "    return bytes(encoded_bytes)\n",
    "\n",
    "input_bytes = bytes([0, 65, 65, 65, 66, 66, 66, 67, 67, 68, 65, 65])\n",
    "encoded_result = encoding(input_bytes)\n",
    "print(list(encoded_result)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "\n",
    "class DCT:\n",
    "    \n",
    "    def encode_dct(self, input):    \n",
    "        return dct(input, type=2, norm='ortho')\n",
    "    \n",
    "    def decode_dct(self, input_inverse):\n",
    "        return idct(input_inverse, type=2, norm='ortho')\n",
    "\n",
    "# Example:\n",
    "if __name__ == \"__main__\":\n",
    "    dct_processor = DCT()\n",
    "\n",
    "    input = np.array([\n",
    "        [52, 55, 61, 66, 70, 61, 64, 73],\n",
    "        [63, 59, 66, 90, 109, 85, 69, 72],\n",
    "        [62, 59, 68, 113, 144, 104, 66, 73],\n",
    "        [63, 58, 71, 122, 154, 106, 70, 69],\n",
    "        [67, 61, 68, 104, 126, 88, 68, 70],\n",
    "        [79, 65, 60, 70, 77, 68, 58, 75],\n",
    "        [85, 71, 64, 59, 55, 61, 65, 83],\n",
    "        [87, 79, 69, 68, 65, 76, 78, 94]\n",
    "    ])\n",
    "\n",
    "    # Apply DCT\n",
    "    dct_encode = dct_processor.encode_dct(input)\n",
    "    print(\"DCT Result:\\n\", dct_encode)\n",
    "\n",
    "    # Apply IDCT \n",
    "    reconstructed_block = dct_processor.decode_dct(dct_encode)\n",
    "    print(\"\\nReconstructed Block:\\n\", reconstructed_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "\n",
    "class DWT:\n",
    "    def __init__(self, wavelet='db2', mode='smooth'):\n",
    "        self.wavelet = wavelet  # db1: simplest wavelet. db2:used for more complex transformations\n",
    "        self.mode = mode        # boundary handling. smooth: smooth continuity at the boundaries. periodic: periodic data\n",
    "\n",
    "    def encode_dwt(self, input_signal):\n",
    "        \n",
    "        cA, cD = pywt.dwt(input_signal, self.wavelet, self.mode)\n",
    "        return cA, cD\n",
    "    \n",
    "    def decode_dwt(self, cA, cD):\n",
    "\n",
    "        return pywt.idwt(cA, cD, self.wavelet, self.mode)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    wavelet_processor = DWT(wavelet='db2', mode='smooth')\n",
    "    \n",
    "    input_signal = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    cA, cD = wavelet_processor.encode_dwt(input_signal)\n",
    "    print(\"Approximation coefficients (cA):\", cA)\n",
    "    print(\"Detail coefficients (cD):\", cD)\n",
    "    \n",
    "    reconstructed_signal = wavelet_processor.decode_dwt(cA, cD)\n",
    "    print(\"\\nReconstructed Signal:\", reconstructed_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed and converted image saved at: /Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/output_image_compressed.jpeg\n",
      "\n",
      "Resized image saved to /Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/resized_image.jpg\n",
      "\n",
      "Resized image saved to /Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_resize.jpeg\n",
      "Original Matrix in BW:\n",
      "[[231 224 148 141 141 148 224 231]\n",
      " [209 208 141 140 140 141 208 209]\n",
      " [211 210 143 142 142 143 210 211]\n",
      " [238 225 141 129 129 141 225 238]\n",
      " [246 220 117  90  90 117 220 246]\n",
      " [225 200  99  74  74  99 200 225]\n",
      " [212 206 132 126 126 132 206 212]\n",
      " [219 232 185 199 199 185 232 219]]\n",
      "Matrix after serpentine in BW:\n",
      "[231, 224, 209, 211, 208, 148, 141, 141, 210, 238, 246, 225, 143, 140, 141, 148, 140, 142, 141, 220, 225, 212, 200, 117, 129, 142, 141, 224, 231, 208, 143, 129, 90, 99, 206, 219, 232, 132, 74, 90, 141, 210, 209, 211, 225, 117, 74, 126, 185, 199, 126, 99, 220, 238, 246, 200, 132, 199, 185, 206, 225, 212, 232, 219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resized image saved to /Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_resize.jpeg\n",
      "Original Matrix in RGB:\n",
      "[[[ 20 252 255]\n",
      "  [ 40 240 255]\n",
      "  [ 17 153 187]\n",
      "  [ 29 143 180]\n",
      "  [ 17 145 180]\n",
      "  [  0 158 187]\n",
      "  [ 33 241 255]\n",
      "  [ 18 252 255]]\n",
      "\n",
      " [[  0 230 248]\n",
      "  [ 24 224 247]\n",
      "  [ 10 146 180]\n",
      "  [ 28 142 179]\n",
      "  [ 16 144 179]\n",
      "  [  0 151 180]\n",
      "  [ 17 225 247]\n",
      "  [  0 230 248]]\n",
      "\n",
      " [[  0 232 250]\n",
      "  [ 26 226 249]\n",
      "  [ 12 148 182]\n",
      "  [ 30 144 181]\n",
      "  [ 18 146 181]\n",
      "  [  0 153 182]\n",
      "  [ 19 227 249]\n",
      "  [  0 232 250]]\n",
      "\n",
      " [[ 27 255 255]\n",
      "  [ 41 241 255]\n",
      "  [ 10 146 180]\n",
      "  [ 17 131 168]\n",
      "  [  5 133 168]\n",
      "  [  0 151 180]\n",
      "  [ 34 242 255]\n",
      "  [ 25 255 255]]\n",
      "\n",
      " [[ 35 255 255]\n",
      "  [ 36 236 255]\n",
      "  [  0 122 156]\n",
      "  [  0  92 129]\n",
      "  [  0  94 129]\n",
      "  [  0 127 156]\n",
      "  [ 29 237 255]\n",
      "  [ 33 255 255]]\n",
      "\n",
      " [[ 14 246 255]\n",
      "  [ 16 216 239]\n",
      "  [  0 104 138]\n",
      "  [  0  76 113]\n",
      "  [  0  78 113]\n",
      "  [  0 109 138]\n",
      "  [  9 217 239]\n",
      "  [ 12 246 255]]\n",
      "\n",
      " [[  1 233 251]\n",
      "  [ 22 222 245]\n",
      "  [  1 137 171]\n",
      "  [ 14 128 165]\n",
      "  [  2 130 165]\n",
      "  [  0 142 171]\n",
      "  [ 15 223 245]\n",
      "  [  0 233 251]]\n",
      "\n",
      " [[  8 240 255]\n",
      "  [ 48 248 255]\n",
      "  [ 54 190 224]\n",
      "  [ 87 201 238]\n",
      "  [ 75 203 238]\n",
      "  [ 33 195 224]\n",
      "  [ 41 249 255]\n",
      "  [  6 240 255]]]\n",
      "Serpentine traversal output for channel 0:\n",
      "[20, 40, 0, 0, 24, 17, 29, 10, 26, 27, 35, 41, 12, 28, 17, 0, 16, 30, 10, 36, 14, 1, 16, 0, 17, 18, 0, 33, 18, 17, 0, 5, 0, 0, 22, 8, 48, 1, 0, 0, 0, 19, 0, 0, 34, 0, 0, 14, 54, 87, 2, 0, 29, 25, 33, 9, 0, 75, 33, 15, 12, 0, 41, 6]\n",
      "Serpentine traversal output for channel 1:\n",
      "[252, 240, 230, 232, 224, 153, 143, 146, 226, 255, 255, 241, 148, 142, 145, 158, 144, 144, 146, 236, 246, 233, 216, 122, 131, 146, 151, 241, 252, 225, 153, 133, 92, 104, 222, 240, 248, 137, 76, 94, 151, 227, 230, 232, 242, 127, 78, 128, 190, 201, 130, 109, 237, 255, 255, 217, 142, 203, 195, 223, 246, 233, 249, 240]\n",
      "Serpentine traversal output for channel 2:\n",
      "[255, 255, 248, 250, 247, 187, 180, 180, 249, 255, 255, 255, 182, 179, 180, 187, 179, 181, 180, 255, 255, 251, 239, 156, 168, 181, 180, 255, 255, 247, 182, 168, 129, 138, 245, 255, 255, 171, 113, 129, 180, 249, 248, 250, 255, 156, 113, 165, 224, 238, 165, 138, 255, 255, 255, 239, 171, 238, 224, 245, 255, 251, 255, 255]\n",
      "Matrix after serpentine in RGB:\n",
      "[[[ 20 252 255]\n",
      "  [ 40 240 255]\n",
      "  [  0 230 248]\n",
      "  [  0 232 250]\n",
      "  [ 24 224 247]\n",
      "  [ 17 153 187]\n",
      "  [ 29 143 180]\n",
      "  [ 10 146 180]]\n",
      "\n",
      " [[ 26 226 249]\n",
      "  [ 27 255 255]\n",
      "  [ 35 255 255]\n",
      "  [ 41 241 255]\n",
      "  [ 12 148 182]\n",
      "  [ 28 142 179]\n",
      "  [ 17 145 180]\n",
      "  [  0 158 187]]\n",
      "\n",
      " [[ 16 144 179]\n",
      "  [ 30 144 181]\n",
      "  [ 10 146 180]\n",
      "  [ 36 236 255]\n",
      "  [ 14 246 255]\n",
      "  [  1 233 251]\n",
      "  [ 16 216 239]\n",
      "  [  0 122 156]]\n",
      "\n",
      " [[ 17 131 168]\n",
      "  [ 18 146 181]\n",
      "  [  0 151 180]\n",
      "  [ 33 241 255]\n",
      "  [ 18 252 255]\n",
      "  [ 17 225 247]\n",
      "  [  0 153 182]\n",
      "  [  5 133 168]]\n",
      "\n",
      " [[  0  92 129]\n",
      "  [  0 104 138]\n",
      "  [ 22 222 245]\n",
      "  [  8 240 255]\n",
      "  [ 48 248 255]\n",
      "  [  1 137 171]\n",
      "  [  0  76 113]\n",
      "  [  0  94 129]]\n",
      "\n",
      " [[  0 151 180]\n",
      "  [ 19 227 249]\n",
      "  [  0 230 248]\n",
      "  [  0 232 250]\n",
      "  [ 34 242 255]\n",
      "  [  0 127 156]\n",
      "  [  0  78 113]\n",
      "  [ 14 128 165]]\n",
      "\n",
      " [[ 54 190 224]\n",
      "  [ 87 201 238]\n",
      "  [  2 130 165]\n",
      "  [  0 109 138]\n",
      "  [ 29 237 255]\n",
      "  [ 25 255 255]\n",
      "  [ 33 255 255]\n",
      "  [  9 217 239]]\n",
      "\n",
      " [[  0 142 171]\n",
      "  [ 75 203 238]\n",
      "  [ 33 195 224]\n",
      "  [ 15 223 245]\n",
      "  [ 12 246 255]\n",
      "  [  0 233 251]\n",
      "  [ 41 249 255]\n",
      "  [  6 240 255]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.322s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "\n",
    "class TestRGBtoYUV(unittest.TestCase):\n",
    "    def test_YUV_to_RGB(self):\n",
    "        yuv_converter = RGBto_YUV()\n",
    "        R, G, B = yuv_converter.YUV_to_RGB(16, 128, 128)\n",
    "        self.assertEqual((R, G, B), (0, 0, 0), \"YUV to RGB conversion for (16,128,128) should be (0,0,0)\")\n",
    "\n",
    "    def test_RGB_to_YUV(self):\n",
    "        yuv_converter = RGBto_YUV()\n",
    "        Y, U, V = yuv_converter.RGB_to_YUV(0, 0, 0)\n",
    "        self.assertEqual((Y, U, V), (16, 128, 128), \"RGB to YUV conversion for (0,0,0) should be (16,128,128)\")\n",
    "\n",
    "class TestResizeImage(unittest.TestCase):\n",
    "    def test_resize_image_success(self):\n",
    "        input_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_1.jpg\"\n",
    "        output_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/resized_image.jpg\"\n",
    "        width = 320\n",
    "        height = 240\n",
    "        quality = 28\n",
    "\n",
    "        # Llamar a la función sin \"mock\"\n",
    "        resize_image(input_image, output_image, width, height, quality)\n",
    "\n",
    "        # Verificar si el archivo se creó\n",
    "        import os\n",
    "        self.assertTrue(os.path.exists(output_image), \"El archivo de salida no se creó correctamente\")\n",
    "        \n",
    "        \n",
    "class TestSerpentine(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        # Input image       \n",
    "        self.image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb.jpeg\"\n",
    "        self.input_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_resize_serpentine.jpeg\"\n",
    "        resize_image(image, input_image, 8, 8, quality=28) #We resize it, to obtain a nxn matrix. \n",
    "\n",
    "    def test_serpentine_bw(self):\n",
    "    \n",
    "        image_bw = cv2.imread(self.input_image, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Check if we have load correctly the image\n",
    "        self.assertIsNotNone(image_bw, \"Failed to load the image in BW\")\n",
    "\n",
    "        # Check if the image is (nxn)\n",
    "        self.assertEqual(image_bw.shape[0], image_bw.shape[1], \"The BW image is not nxn\")\n",
    "        \n",
    "        # Print matrix image\n",
    "        print(\"Original Matrix in BW:\")\n",
    "        print(image_bw)\n",
    "\n",
    "        # We apply the function\n",
    "        serpentine_result = serpentine(image_bw)\n",
    "        \n",
    "        # print of the result\n",
    "        print(\"Matrix after serpentine in BW:\")\n",
    "        print(serpentine_result)\n",
    "\n",
    "        # Check if the result is correct. \n",
    "        self.assertEqual(len(serpentine_result), image_bw.size, \"Serpentine result has incorrect size\")\n",
    "\n",
    "    def test_serpentine_color(self):\n",
    "        \n",
    "        image_rgb = cv2.imread(self.input_image)\n",
    "\n",
    "        # Check if we have load correctly the image\n",
    "        self.assertIsNotNone(image_rgb, \"Failed to load the RGB image\")\n",
    "\n",
    "        # Check if the image is (nxn)\n",
    "        self.assertEqual(image_rgb.shape[0], image_rgb.shape[1], \"The RGB image is not nxn\")\n",
    "        \n",
    "        # Print matrix image\n",
    "        print(\"Original Matrix in RGB:\")\n",
    "        print(image_rgb)\n",
    "\n",
    "        # We apply the function\n",
    "        serpentine_result = serpentine_color(image_rgb)\n",
    "        \n",
    "        # print of the result\n",
    "        print(\"Matrix after serpentine in RGB:\")\n",
    "        print(serpentine_result)\n",
    "\n",
    "        # Check if the result is correct. \n",
    "        self.assertEqual(serpentine_result.shape, image_rgb.shape, \"The serpentine color result has incorrect size\")\n",
    "\n",
    "        # Check if the 3 channels are correctly transformed\n",
    "        red_channel, green_channel, blue_channel = cv2.split(serpentine_result)\n",
    "\n",
    "        # Check if each channel has the same size as the original image\n",
    "        self.assertEqual(red_channel.shape, image_rgb.shape[:2], \"Red channel size mismatch\")\n",
    "        self.assertEqual(green_channel.shape, image_rgb.shape[:2], \"Green channel size mismatch\")\n",
    "        self.assertEqual(blue_channel.shape, image_rgb.shape[:2], \"Blue channel size mismatch\")\n",
    "\n",
    "class TestCompressToBW(unittest.TestCase):\n",
    "\n",
    "    def test_compress_to_bw_success(self):\n",
    "        # Define the paths (you can use actual image paths for testing)\n",
    "        input_image_path = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb.jpeg\"\n",
    "        output_image_path =  \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/output_image_compressed.jpeg\"\n",
    "\n",
    "        # Ensure the output path doesn't exist before running the test\n",
    "        if os.path.exists(output_image_path):\n",
    "            os.remove(output_image_path)\n",
    "\n",
    "        # Call the function\n",
    "        compress_to_bw(input_image_path, output_image_path)\n",
    "        \n",
    "        # Check if the output image was created\n",
    "        self.assertTrue(os.path.exists(output_image_path), \"Output image was not created\")\n",
    "\n",
    "\n",
    "# Ejecuta las pruebas\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMRLfTamI1Guef8I/9SvpXQ",
   "mount_file_id": "1zG2m0ccomnArDcFgJIhztc_vM1FDdex0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

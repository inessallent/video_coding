{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUkA7KW-vKAq"
   },
   "source": [
    "# Seminar_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBto_YUV:\n",
    "    def YUV_to_RGB(self, Y,U,V):\n",
    "        B = round(1.163 * (Y -16) + 2.018 * (U - 128))\n",
    "        G = round(1.164 * (Y - 16) - 0.813 * (V - 128) - 0.391 * (U - 128))\n",
    "        R = round(1.164 * (Y - 16) + 1.596 * (V - 128)) \n",
    "        return(R, G, B)\n",
    "    \n",
    "    def RGB_to_YUV(self, R,G,B):\n",
    "        Y = round(0.257 * R + 0.504 * G + 0.098 * B +16)\n",
    "        U = round(-0.148 * R - 0.291 * G + 0.439 * B +128)\n",
    "        V = round(0.439 * R - 0.368 * G - 0.071 * B +128)\n",
    "        return(Y,U,V)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores RGB: R = 98, G = 98, B = 98\n"
     ]
    }
   ],
   "source": [
    "Y, U, V = 100, 128, 128\n",
    "\n",
    "# Convertir YUV a RGB\n",
    "converter = RGBto_YUV()\n",
    "R, G, B = converter.YUV_to_RGB(Y, U, V)\n",
    "print(f\"Valores RGB: R = {R}, G = {G}, B = {B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores YUV: Y = 100, U = 128, V = 128\n"
     ]
    }
   ],
   "source": [
    "# Convertir RGB a YUV\n",
    "Y, U, V = converter.RGB_to_YUV(R, G, B)\n",
    "print(f\"Valores YUV: Y = {Y}, U = {U}, V = {V}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "def resize_image(input_image, output_image, width, height, quality = 28):\n",
    "\n",
    "    command = [\"ffmpeg\",\"-y\",\"-loglevel\", \"info\",\"-i\", input_image,\"-vf\", f\"scale={width}:{height}\"]\n",
    "\n",
    "    if quality is not None:\n",
    "        command.extend([\"-q:v\", str(quality)])\n",
    "    \n",
    "    command.append(output_image)\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(result.stdout)\n",
    "        print(f\"Resized image saved to {output_image}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error ocurred while running FFmpeg\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "We first implement it with a matrix 8x8 in order to check if the algorithm is really working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz 8x8:\n",
      "[[ 1  2  3  4  5  6  7  8]\n",
      " [ 9 10 11 12 13 14 15 16]\n",
      " [17 18 19 20 21 22 23 24]\n",
      " [25 26 27 28 29 30 31 32]\n",
      " [33 34 35 36 37 38 39 40]\n",
      " [41 42 43 44 45 46 47 48]\n",
      " [49 50 51 52 53 54 55 56]\n",
      " [57 58 59 60 61 62 63 64]]\n",
      "\n",
      "Recorrido Zig-Zag:\n",
      "[1, 2, 9, 17, 10, 3, 4, 11, 18, 25, 33, 26, 19, 12, 5, 6, 13, 20, 27, 34, 41, 49, 42, 35, 28, 21, 14, 7, 8, 15, 22, 29, 36, 43, 50, 57, 58, 51, 44, 37, 30, 23, 16, 24, 31, 38, 45, 52, 59, 60, 53, 46, 39, 32, 40, 47, 54, 61, 62, 55, 48, 56, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.arange(1, 65).reshape(8, 8)\n",
    "\n",
    "def zigzag_traversal(matrix):\n",
    "    result = [None] * 64  \n",
    "    n = matrix.shape[0]  \n",
    "    \n",
    "    a = 0  \n",
    "    i = 0 \n",
    "    j = 0 \n",
    "    result[a] = matrix[i][j]  # First value\n",
    "    \n",
    "    while a < 63:  \n",
    "        #step 1: (one to the right)\n",
    "        if j == n - 1:  \n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < 64:\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 2: (Diagonal down to the left until reaching j = 0)\n",
    "        while i + 1 < n and j - 1 >= 0 and a < 63:\n",
    "            i += 1\n",
    "            j -= 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 3: (one down) \n",
    "        if i == n - 1:  \n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < 64:\n",
    "            result[a] = matrix[i][j]\n",
    "        \n",
    "        #step 4: (Diagonal up to the right until reaching i = 0)\n",
    "        while j + 1 < n and i - 1 >= 0 and a < 63:\n",
    "            i -= 1\n",
    "            j += 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i][j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Obtener el recorrido zig-zag\n",
    "zigzag_result = zigzag_traversal(matrix)\n",
    "\n",
    "# Mostrar la matriz y el recorrido zig-zag\n",
    "print(\"Matriz 8x8:\")\n",
    "print(matrix)\n",
    "print(\"\\nRecorrido Zig-Zag:\")\n",
    "print(zigzag_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we implemented for images. We use the resize_image function generated in the previous exercise in order to obtain a nxn image. Then we implement the zig zag function and obtain the expected output. First we implemented in Black and White, but then we realize that maybe it was needed to implemented for rgb images, so we added it to the code.\n",
    "\n",
    "We can try and change the values of the resize image. In order to check if the algorithm is still working for this case with images, we have set the values to 16, because then we can see the complete matrix. \n",
    "Then we change it to a bigger value, 420 in this case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image_bw\u001b[39m(image_path):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess\n",
    "\n",
    "def load_image_bw(image_path):\n",
    "    return cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n",
    "\n",
    "def load_image_rgb(image_path):\n",
    "    return cv2.imread(image_path)  \n",
    "\n",
    "def serpentine(matrix):\n",
    "    n = matrix.shape[0]  \n",
    "    result = [None] * (n * n)  \n",
    "    \n",
    "    a = 0  \n",
    "    i = 0 \n",
    "    j = 0 \n",
    "    result[a] = matrix[i, j]  # First value\n",
    "    \n",
    "    while a < n * n - 1:  \n",
    "        #step 1: (one to the right)\n",
    "        if j == n - 1:  \n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < n * n:\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 2: (Diagonal down to the left until reaching j = 0)\n",
    "        while i + 1 < n and j - 1 >= 0 and a < n * n - 1:\n",
    "            i += 1\n",
    "            j -= 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 3: (one down)\n",
    "        if i == n - 1:  \n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        a += 1\n",
    "        if a < n * n:\n",
    "            result[a] = matrix[i, j]\n",
    "        \n",
    "        #step 4: (Diagonal up to the right until reaching i = 0)\n",
    "        while j + 1 < n and i - 1 >= 0 and a < n * n - 1:\n",
    "            i -= 1\n",
    "            j += 1\n",
    "            a += 1\n",
    "            result[a] = matrix[i, j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Inputs and Outputs\n",
    "image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb.jpeg\"\n",
    "input_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_resize.jpeg\"\n",
    "resize_image(image, input_image, 420, 420, quality=28)\n",
    "# output_image_bw = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/serpentine_bw.jpeg\"\n",
    "# output_image_rgb = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/serpentine_rgb.jpeg\"\n",
    "\n",
    "##################### Black and White case #####################################\n",
    "\n",
    "# #We load the resize image in BW\n",
    "# image_bw = load_image_bw(input_image)\n",
    "\n",
    "# if image_bw is None:\n",
    "#     print(\"Error loading the BW image\")\n",
    "# else:\n",
    "#     # Print the matrix to then check it the convertion is done well. \n",
    "#     print(\"Original Matrix in Black and White:\")\n",
    "#     print(image_bw)\n",
    "\n",
    "\n",
    "# # Check if it's a nxn matrix\n",
    "# if image_bw is None:\n",
    "#     print(\"Error loading the BW image\")\n",
    "# else:\n",
    "#     assert image_bw.shape[0] == image_bw.shape[1], \"The resize BW image is not nxn.\"\n",
    "\n",
    "#     serpentine_result_bw = serpentine(image_bw)\n",
    "\n",
    "#     print(\"Serpentine of image in Black and White:\")\n",
    "#     print(serpentine_result_bw)\n",
    "\n",
    "#     n = image_bw.shape[0]\n",
    "#     serpentine_image_bw = np.array(serpentine_result_bw).reshape((n, n))\n",
    "\n",
    "#     # Safe the output\n",
    "#     # cv2.imwrite(output_image_bw, serpentine_image_bw)\n",
    "#     # print(f\"Output in BW safe in: {output_image_bw}\")\n",
    "\n",
    "\n",
    "############################# RGB CASE ############################\n",
    "def serpentine_color(image):\n",
    "    channels = cv2.split(image)  # Separate into B, G, and R channels\n",
    "    serpentine_channels = []\n",
    "\n",
    "    for idx, channel in enumerate(channels):\n",
    "        serpentine_result = serpentine(channel)\n",
    "        \n",
    "        # Print serpentine result for each channel\n",
    "        print(f\"Serpentine traversal output for channel {idx}:\")\n",
    "        print(serpentine_result)\n",
    "        \n",
    "        n = channel.shape[0]\n",
    "        serpentine_matrix = np.array(serpentine_result).reshape((n, n))\n",
    "        serpentine_channels.append(serpentine_matrix)\n",
    "\n",
    "    # Merge channels back into a color image\n",
    "    serpentine_image_color = cv2.merge(serpentine_channels)\n",
    "    return serpentine_image_color\n",
    "\n",
    "\n",
    "# #We load the resize image in BW\n",
    "# image_rgb = load_image_rgb(input_image)\n",
    "\n",
    "\n",
    "# if image_rgb is None:\n",
    "#     print(\"Error loading the image in rgb\")\n",
    "# else:\n",
    "#     # Print the matrix to then check it the conversion is done well. \n",
    "#     print(\"Original Matrix rgb:\")\n",
    "#     print(image_rgb)\n",
    "\n",
    "\n",
    "# if image_rgb is None:\n",
    "#     print(\"Error loading the image\")\n",
    "# else:\n",
    "#     # Check image is nxn\n",
    "#     assert image_rgb.shape[0] == image_rgb.shape[1], \"Input image rgb is not nxn.\"\n",
    "    \n",
    "#     serpentine_result_rbg = serpentine_color(image_rgb)\n",
    "    \n",
    "#     print(\"Output matrix of rgb image\",serpentine_result_rbg)\n",
    "    \n",
    "#     # cv2.imwrite(output_image_rgb, serpentine_result_rbg)\n",
    "#     # print(f\"Serpentine image in rgb safe in: {output_image_rgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**\n",
    "We transform the rgb output to Black and White. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_to_bw(input_image_path, output_image_path):\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            'ffmpeg', '-i', input_image_path, \n",
    "            '-vf', 'format=gray',  # Convert to black and white\n",
    "            '-compression_level', '10',  # Max compression for PNG (range 0-10)\n",
    "            '-qscale:v', '31',  # Highest compression for JPEG (range 2-31)\n",
    "            '-y', output_image_path\n",
    "        ], check=True)\n",
    "        \n",
    "        print(f\"Compressed and converted image saved at: {output_image_path}\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"FFMPEG failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 3, 65, 3, 66, 2, 67, 1, 68, 2, 65]\n"
     ]
    }
   ],
   "source": [
    "def encoding(byte_sequence):\n",
    "    if not isinstance(byte_sequence, (bytes, bytearray)):\n",
    "        raise ValueError(\"Input must be a bytes or bytearray object.\")\n",
    "    \n",
    "    encoded_bytes = bytearray()\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(byte_sequence):\n",
    "        count = 1\n",
    "        current_byte = byte_sequence[i]\n",
    "        j = i\n",
    "\n",
    "        while j < len(byte_sequence) - 1:\n",
    "            if byte_sequence[j] == byte_sequence[j + 1]:\n",
    "                count += 1\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        encoded_bytes.append(count)\n",
    "        encoded_bytes.append(current_byte)\n",
    "        \n",
    "        i = j + 1\n",
    "    \n",
    "    return bytes(encoded_bytes)\n",
    "\n",
    "#example\n",
    "input_bytes = bytes([0, 65, 65, 65, 66, 66, 66, 67, 67, 68, 65, 65])\n",
    "encoded_result = encoding(input_bytes)\n",
    "print(list(encoded_result)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCT Result:\n",
      " [[177.48380208 -14.43003934  -5.65536258  -6.74138401   7.07106781\n",
      "   -3.08289291  -0.71893958   2.41318823]\n",
      " [216.72822843 -15.7021571  -33.96500451  11.82921573  19.44543648\n",
      "   -7.34845902  -1.62125521   3.31844356]\n",
      " [243.59828612 -21.32862687 -65.34971214  22.37520692  33.58757211\n",
      "  -16.02229259  -1.63252036   1.10721787]\n",
      " [252.08356749 -20.77509775 -75.89507043  24.72899923  36.41599923\n",
      "  -12.49959345  -4.91815858   3.8899967 ]]\n",
      "\n",
      "Reconstructed Block:\n",
      " [[ 52.  55.  61.  66.  70.  61.  64.  73.]\n",
      " [ 63.  59.  66.  90. 109.  85.  69.  72.]\n",
      " [ 62.  59.  68. 113. 144. 104.  66.  73.]\n",
      " [ 63.  58.  71. 122. 154. 106.  70.  69.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "\n",
    "class DCT:\n",
    "    \n",
    "    def encode_dct(self, input):    \n",
    "        return dct(input, type=2, norm='ortho')\n",
    "    \n",
    "    def decode_dct(self, input_inverse):\n",
    "        return idct(input_inverse, type=2, norm='ortho')\n",
    "\n",
    "# example:\n",
    "if __name__ == \"__main__\":\n",
    "    dct_processor = DCT()\n",
    "\n",
    "    input = np.array([\n",
    "        [52, 55, 61, 66, 70, 61, 64, 73],\n",
    "        [63, 59, 66, 90, 109, 85, 69, 72],\n",
    "        [62, 59, 68, 113, 144, 104, 66, 73],\n",
    "        [63, 58, 71, 122, 154, 106, 70, 69],\n",
    "    ])\n",
    "\n",
    "    # DCT\n",
    "    dct_encode = dct_processor.encode_dct(input)\n",
    "    print(\"DCT Result:\\n\", dct_encode)\n",
    "\n",
    "    # IDCT \n",
    "    reconstructed_block = dct_processor.decode_dct(dct_encode)\n",
    "    print(\"\\nReconstructed Block:\\n\", reconstructed_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation coefficients (cA): [-0.51763809  2.31078903  5.13921616  7.96764328]\n",
      "Detail coefficients (cD): [0.00000000e+00 1.66533454e-16 3.33066907e-16 2.22044605e-16]\n",
      "\n",
      "Reconstructed Signal: [1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "\n",
    "class DWT:\n",
    "    def __init__(self, wavelet='db2', mode='smooth'):\n",
    "        self.wavelet = wavelet  # db1: simplest wavelet. db2:used for more complex transformations\n",
    "        self.mode = mode        # boundary handling. smooth: smooth continuity at the boundaries. periodic: periodic data\n",
    "\n",
    "    def encode_dwt(self, input_signal):\n",
    "        \n",
    "        cA, cD = pywt.dwt(input_signal, self.wavelet, self.mode)\n",
    "        return cA, cD\n",
    "    \n",
    "    def decode_dwt(self, cA, cD):\n",
    "\n",
    "        return pywt.idwt(cA, cD, self.wavelet, self.mode)\n",
    "\n",
    "# example\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    wavelet_processor = DWT(wavelet='db2', mode='smooth')\n",
    "    \n",
    "    input_signal = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    cA, cD = wavelet_processor.encode_dwt(input_signal)\n",
    "    print(\"Approximation coefficients (cA):\", cA)\n",
    "    print(\"Detail coefficients (cD):\", cD)\n",
    "    \n",
    "    reconstructed_signal = wavelet_processor.decode_dwt(cA, cD)\n",
    "    print(\"\\nReconstructed Signal:\", reconstructed_signal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E..FEE\n",
      "======================================================================\n",
      "ERROR: test_compress_to_bw_success (__main__.TestCompressToBW)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/wr/kwn4kh2j7nv4yh19zcl_w2_00000gn/T/ipykernel_66789/3221102832.py\", line 107, in test_compress_to_bw_success\n",
      "    compress_to_bw(input_image_path, output_image_path)\n",
      "NameError: name 'compress_to_bw' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_serpentine_bw (__main__.TestSerpentine)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/wr/kwn4kh2j7nv4yh19zcl_w2_00000gn/T/ipykernel_66789/3221102832.py\", line 37, in setUp\n",
      "    resize_image(image, input_image, 8, 8, quality=28) #We resize it, to obtain a nxn matrix.\n",
      "NameError: name 'image' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_serpentine_color (__main__.TestSerpentine)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/wr/kwn4kh2j7nv4yh19zcl_w2_00000gn/T/ipykernel_66789/3221102832.py\", line 37, in setUp\n",
      "    resize_image(image, input_image, 8, 8, quality=28) #We resize it, to obtain a nxn matrix.\n",
      "NameError: name 'image' is not defined\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_resize_image_success (__main__.TestResizeImage)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/wr/kwn4kh2j7nv4yh19zcl_w2_00000gn/T/ipykernel_66789/3221102832.py\", line 28, in test_resize_image_success\n",
      "    self.assertTrue(os.path.exists(output_image), \"El archivo de salida no se creó correctamente\")\n",
      "AssertionError: False is not true : El archivo de salida no se creó correctamente\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 2.282s\n",
      "\n",
      "FAILED (failures=1, errors=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ocurred while running FFmpeg ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[in#0 @ 0x1447064e0] Error opening input: No such file or directory\n",
      "Error opening input file /Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_1.jpg.\n",
      "Error opening input files: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "\n",
    "class TestRGBtoYUV(unittest.TestCase):\n",
    "    def test_YUV_to_RGB(self):\n",
    "        yuv_converter = RGBto_YUV()\n",
    "        R, G, B = yuv_converter.YUV_to_RGB(16, 128, 128)\n",
    "        self.assertEqual((R, G, B), (0, 0, 0), \"YUV to RGB conversion for (16,128,128) should be (0,0,0)\")\n",
    "\n",
    "    def test_RGB_to_YUV(self):\n",
    "        yuv_converter = RGBto_YUV()\n",
    "        Y, U, V = yuv_converter.RGB_to_YUV(0, 0, 0)\n",
    "        self.assertEqual((Y, U, V), (16, 128, 128), \"RGB to YUV conversion for (0,0,0) should be (16,128,128)\")\n",
    "\n",
    "class TestResizeImage(unittest.TestCase):\n",
    "    def test_resize_image_success(self):\n",
    "        input_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_1.jpg\"\n",
    "        output_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/resized_image.jpg\"\n",
    "        width = 320\n",
    "        height = 240\n",
    "        quality = 28\n",
    "\n",
    "        # Llamar a la función sin \"mock\"\n",
    "        resize_image(input_image, output_image, width, height, quality)\n",
    "\n",
    "        # Verificar si el archivo se creó\n",
    "        import os\n",
    "        self.assertTrue(os.path.exists(output_image), \"El archivo de salida no se creó correctamente\")\n",
    "        \n",
    "        \n",
    "class TestSerpentine(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        # Input image       \n",
    "        self.image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb.jpeg\"\n",
    "        self.input_image = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb_resize_serpentine.jpeg\"\n",
    "        resize_image(image, input_image, 8, 8, quality=28) #We resize it, to obtain a nxn matrix. \n",
    "\n",
    "    def test_serpentine_bw(self):\n",
    "    \n",
    "        image_bw = cv2.imread(self.input_image, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Check if we have load correctly the image\n",
    "        self.assertIsNotNone(image_bw, \"Failed to load the image in BW\")\n",
    "\n",
    "        # Check if the image is (nxn)\n",
    "        self.assertEqual(image_bw.shape[0], image_bw.shape[1], \"The BW image is not nxn\")\n",
    "        \n",
    "        # Print matrix image\n",
    "        print(\"Original Matrix in BW:\")\n",
    "        print(image_bw)\n",
    "\n",
    "        # We apply the function\n",
    "        serpentine_result = serpentine(image_bw)\n",
    "        \n",
    "        # print of the result\n",
    "        print(\"Matrix after serpentine in BW:\")\n",
    "        print(serpentine_result)\n",
    "\n",
    "        # Check if the result is correct. \n",
    "        self.assertEqual(len(serpentine_result), image_bw.size, \"Serpentine result has incorrect size\")\n",
    "\n",
    "    def test_serpentine_color(self):\n",
    "        \n",
    "        image_rgb = cv2.imread(self.input_image)\n",
    "\n",
    "        # Check if we have load correctly the image\n",
    "        self.assertIsNotNone(image_rgb, \"Failed to load the RGB image\")\n",
    "\n",
    "        # Check if the image is (nxn)\n",
    "        self.assertEqual(image_rgb.shape[0], image_rgb.shape[1], \"The RGB image is not nxn\")\n",
    "        \n",
    "        # Print matrix image\n",
    "        print(\"Original Matrix in RGB:\")\n",
    "        print(image_rgb)\n",
    "\n",
    "        # We apply the function\n",
    "        serpentine_result = serpentine_color(image_rgb)\n",
    "        \n",
    "        # print of the result\n",
    "        print(\"Matrix after serpentine in RGB:\")\n",
    "        print(serpentine_result)\n",
    "\n",
    "        # Check if the result is correct. \n",
    "        self.assertEqual(serpentine_result.shape, image_rgb.shape, \"The serpentine color result has incorrect size\")\n",
    "\n",
    "        # Check if the 3 channels are correctly transformed\n",
    "        red_channel, green_channel, blue_channel = cv2.split(serpentine_result)\n",
    "\n",
    "        # Check if each channel has the same size as the original image\n",
    "        self.assertEqual(red_channel.shape, image_rgb.shape[:2], \"Red channel size mismatch\")\n",
    "        self.assertEqual(green_channel.shape, image_rgb.shape[:2], \"Green channel size mismatch\")\n",
    "        self.assertEqual(blue_channel.shape, image_rgb.shape[:2], \"Blue channel size mismatch\")\n",
    "\n",
    "class TestCompressToBW(unittest.TestCase):\n",
    "\n",
    "    def test_compress_to_bw_success(self):\n",
    "        # Define the paths (you can use actual image paths for testing)\n",
    "        input_image_path = \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/logo_fcb.jpeg\"\n",
    "        output_image_path =  \"/Users/isall/OneDrive/UNI/4_uni/1_trim_4/Audio/video_coding/seminar1/output_image_compressed.jpeg\"\n",
    "\n",
    "        # Ensure the output path doesn't exist before running the test\n",
    "        if os.path.exists(output_image_path):\n",
    "            os.remove(output_image_path)\n",
    "\n",
    "        # Call the function\n",
    "        compress_to_bw(input_image_path, output_image_path)\n",
    "        \n",
    "        # Check if the output image was created\n",
    "        self.assertTrue(os.path.exists(output_image_path), \"Output image was not created\")\n",
    "\n",
    "\n",
    "# Ejecuta las pruebas\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".............\n",
      "----------------------------------------------------------------------\n",
      "Ran 13 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestEncoding(unittest.TestCase):\n",
    "    def test_encoding(self):\n",
    "        input_bytes = bytes([0, 65, 65, 65, 66, 66, 66, 67, 67, 68, 65, 65])\n",
    "        encoded = encoding(input_bytes)\n",
    "        self.assertEqual(list(encoded), [1, 0, 3, 65, 3, 66, 2, 67, 1, 68, 2, 65])\n",
    "\n",
    "    def test_encoding_non_bytes_input(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            encoding([1, 2, 3])  # Input that is not a byte sequence\n",
    "\n",
    "class TestDCT(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.dct_processor = DCT()\n",
    "        self.input_block = np.array([\n",
    "            [52, 55, 61, 66, 70, 61, 64, 73],\n",
    "            [63, 59, 66, 90, 109, 85, 69, 72],\n",
    "            [62, 59, 68, 113, 144, 104, 66, 73],\n",
    "            [63, 58, 71, 122, 154, 106, 70, 69],\n",
    "            [67, 61, 68, 104, 126, 88, 68, 70],\n",
    "            [79, 65, 60, 70, 77, 68, 58, 75],\n",
    "            [85, 71, 64, 59, 55, 61, 65, 83],\n",
    "            [87, 79, 69, 68, 65, 76, 78, 94]\n",
    "        ])\n",
    "\n",
    "    def test_encode_dct(self):\n",
    "        dct_result = self.dct_processor.encode_dct(self.input_block)\n",
    "        self.assertIsNotNone(dct_result)  # Ensure result is not None\n",
    "\n",
    "    def test_decode_dct(self):\n",
    "        dct_result = self.dct_processor.encode_dct(self.input_block)\n",
    "        reconstructed = self.dct_processor.decode_dct(dct_result)\n",
    "        np.testing.assert_array_almost_equal(self.input_block, reconstructed, decimal=0)\n",
    "\n",
    "class TestDWT(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.wavelet_processor = DWT(wavelet='db2', mode='smooth')\n",
    "        self.input_signal = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    def test_encode_dwt(self):\n",
    "        cA, cD = self.wavelet_processor.encode_dwt(self.input_signal)\n",
    "        self.assertIsNotNone(cA)\n",
    "        self.assertIsNotNone(cD)\n",
    "\n",
    "    def test_decode_dwt(self):\n",
    "        cA, cD = self.wavelet_processor.encode_dwt(self.input_signal)\n",
    "        reconstructed_signal = self.wavelet_processor.decode_dwt(cA, cD)\n",
    "        np.testing.assert_array_almost_equal(self.input_signal, reconstructed_signal, decimal=1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMRLfTamI1Guef8I/9SvpXQ",
   "mount_file_id": "1zG2m0ccomnArDcFgJIhztc_vM1FDdex0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
